<!DOCTYPE html>
<html>

    <head>
        <title>colinswaney</title>
        <link rel="icon" type="image/png" href="/favicon.ico">
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <!-- UIKit -->
        <link rel="stylesheet" href="/assets/css/uikit.min.css"/>
        <link rel="stylesheet" href="/assets/css/theme.css"/>
        <script src="/assets/js/uikit.min.js"></script>
        <script src="/assets/js/uikit-icons.min.js"></script>
        <!-- Prism -->
        <!-- <link rel="stylesheet" href="/assets/css/prism.css"/>
        <script src="/assets/js/prism.js"></script> -->
        <!-- Highlight Rouge -->
        <!-- <link rel="stylesheet" href="/assets/css/syntax.css"/> -->
        <link rel="stylesheet" href="/assets/css/base16.css"/>
        <!-- Highlightjs -->
        <!-- <link rel="stylesheet" href="/assets/highlight/default.css"/>
        <script src="/assets/highlight/highlight.pack.js"></script> -->
        <!-- GoogleFonts -->
        <link rel="preconnect" href="https://fonts.gstatic.com">
        <link href="https://fonts.googleapis.com/css?family=Lora" rel="stylesheet">
        <link href="https://fonts.googleapis.com/css?family=Fjalla+One" rel="stylesheet">
        <link href="https://fonts.googleapis.com/css2?family=Indie+Flower&display=swap" rel="stylesheet">
        <!-- KaTeX -->
        <script src="//code.jquery.com/jquery-1.11.1.min.js"></script>
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css">
        <script src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.js"></script>
    </head>

    <body class="uk-background uk-height-viewport">

        <div class="tm-navbar-container" uk-sticky="animation: uk-animation-slide-top; sel-target: .uk-navbar-container; cls-active: uk-navbar-sticky; cls-inactive: uk-navbar-transparent; top: 300">

    <nav class="uk-navbar-container" uk-navbar style="position: relative; z-index: 980;">

        <div class="uk-navbar-center">

            <div class="uk-navbar-center-left">
                <div>
                    <ul class="uk-navbar-nav">
                        
                            <li class="uk-active"><a class="tm-navbar-item" href="/index.html">Blog</a></li>
                        
                    </ul>
                </div>
            </div>

            <a class="uk-navbar-item uk-logo" href="#">
                <img uk-svg src="/assets/img/wave.png" style="width: 56px; height: 56px;">
            </a>

            <div class="uk-navbar-center-right">
                <div>
                    <ul class="uk-navbar-nav">
                        
                            <li><a class="tm-navbar-item" href="/info.html">Info</a></li>
                        
                        <!-- <li>
                            <a href="https://github.com/cswaney" uk-icon="icon: github; ratio: 1.5"></a>
                        </li>
                        <li>
                            <a href="https://twitter.com/SwaneyColin?lang=en" uk-icon="icon: twitter; ratio: 1.5"></a>
                        </li> -->
                    </ul>
                </div>
            </div>

        </div>

    </nav>

</div>


        <div class="uk-section uk-section-default uk-section-small uk-padding-remove-top uk-margin-small-top">
        <!-- <div class="uk-section uk-section-default uk-section-small uk-margin-large-top"> -->

                <div class="uk-container uk-container-small uk-position-relative uk-height-viewport">

    <div>
        <article class="uk-article uk-margin-large-top">

            <!-- <h1 class="uk-article-title"><a class="uk-link-reset" href="">Event Models</a></h1> -->
            <h1 class="uk-article-title">Event Models</h1>

            <!-- <p class="uk-article-meta tm-article-meta">Written by <a href="#">Colin Swaney</a> on Saturday, April 25, 2020</a></p> -->
            <p class="uk-article-meta tm-article-meta">Saturday, April 25, 2020</p>

            <!-- tags... -->

            <!-- I want to discuss a machine learning algorithm that transformed my understanding of what machine learning is, or rather what it *can be* in the hands of a strong mind. The class of models I want to discuss are rather complicated, but I hope to hold your hand through the process so that you can understand what is going on and hopefully illuminate to the model's brilliance and underlying simplicity.

To set the scene, imagine we wish to predict the occurrence of a stream of events. The events come from a variety of related sources or "channels". (The paper that developed this model was motivated by computational neuroscience research, so you can think of these channels as being neurons and the events as electric impulses being fired off). We want to quantify the probability of an event on each of these channels in real-time, but we would also like a model that is interpretable, allowing us to understand the structure of the system.


## Network Models


### Spike-and-Slab
So-called "spike-and-slab" models separate concerns between the existence of connections in a network and the strength of those connections. In particular, the network is represented by a random matrix of the form

$$ A \odot W, $$

where $$A$$ is a binary matrix and $$W \in \mathbb{R}^{N \times N}$$. $$A$$ represents the presence of a connection between nodes; $$W$$ captures the strength of the connection. To simplify, let's ignore $$W$$ for a moment and focus our attention on the connection matrix, $$A$$. How we chose to model $$A$$ reflects our understanding and beliefs about the nature of the system we are investigating. Consider the following three popular models:

#### Erdös-Rényi Network
In the Erdös-Rényi model, each connection in the model ($$a_{i, j}$$) is sampled independently from a \text{Bern} distribution:

$$a_{i, j} \sim \text{Bern}(\rho)$$

This modeling approach reflects a *lack* of structure in the network.

#### Stochastic Block Network
The Stochastic Block model adds (latent) structure to the network by assigning a class, $$z_i$$, to each node. Connections are sampled independently *conditional* on their class:

$$ a_{i, j} \sim \text{Bern}(\rho_{z_i}, \rho_{z_j}), $$

where $$z_k$$ is the latent class of the $$k$$-th node. The latent class itself requires a prior distribution, and a standard choice is a compound discrete distribution:

$$ z_i \sim \text{Discrete}(\pi), $$

$$ \pi \sim \text{Dir}(\alpha \mathbf{1}_K).$$

This approach is analogous to a Gaussian mixture model and reflects a belief that connections between particular nodes are more or less likely.

#### Latent Distance Network
If nodes are associated with characteristics/features, then it may be appropriate to model the likelihood of connections as dependent on the similarity between these features. In the Latent Distance Network, the distance between networks determines the probability of a connection between nodes. For a given metric, $$\| \cdot \|$$, the probability of a connection between nodes is

$$ p(a_{i, j} = 1 \ | \ z) = \sigma \left( - \| z_i -z_j \|_2^2 + \gamma_0 \right) $$

The features $$z$$ can be either observed features or latent class features. In the latter case, we need to specify a prior distribution of latent locations. A Normal-InverseGamma prior is a standard choice:

$$ z_i \sim \mathcal{N} (0, \tau I), $$

$$ \tau \sim \text{IGa}(1, 1).$$ -->

<!-- ## Outline

I. Poisson Processes
	a. Continuous
	b. Discrete
	c. Multivariate

II. Hawkes Process
	a. Continuous
	b. Discrete
	c. Multivariate

III. Inference
	a. Maximum-Likelihood Estimation
	b. Markov Chain Monte Carlo
	c. Variational Inference -->

<h2 id="i-poisson-processes">I. Poisson Processes</h2>

<p>Continuous point processes model sequences of events <script type="math/tex">\{s_m\}_{m=1}^M</script>. Typically, <script type="math/tex">s_m</script> denotes the time at which an event occurs, <script type="math/tex">s_m \in \left[0, T\right]</script>, but it could just as well represent the location where an event occurs, <script type="math/tex">s_m \in \mathbb{R}^D</script>. For now, we will consider the point processes as a univariate process that measures a single type of event; in general, a point process can represent multiple—possibly interacting—event streams.</p>

<p>A <em>Poisson process</em> is a point process in which the probability of events is determined by an intensity function <script type="math/tex">\lambda(t)</script> such that the number of events that occur in a period <script type="math/tex">\left[t, t + \Delta t \right]</script> has a Poisson distribution,</p>

<script type="math/tex; mode=display">M \sim \text{Poisson}\left(\int_{t}^{t + \Delta t} \lambda(t) dt \right),</script>

<p>and the number of events in non-overlapping periods <script type="math/tex">\mathcal{V}</script> and <script type="math/tex">\mathcal{W}</script> are independent.</p>

<h3 id="simulation">Simulation</h3>
<p>There is general method for simulating a Poisson process. It consists of sampling a number of events according to the Poisson distribution above, then sampling the time of these events according to the distribution of <script type="math/tex">\lambda(t)</script> throuhout <script type="math/tex">\left[0, T\right]</script>,</p>

<script type="math/tex; mode=display">s_m \sim p(s) = \frac{\lambda(t)}{\int_0^T \lambda(t) dt}.</script>

<p>The first step ensures that the number of events reflects the aggregate intensity; the second step forces the timing of events to match the variation in intensity over time.</p>

<h3 id="likelihood">Likelihood</h3>
<p>The likelihood of a sequence of events generated according to a Poisson process is calculated in an analogous fashion to the simulation process. First, calculate the probability of observing <script type="math/tex">M</script> events,</p>

<script type="math/tex; mode=display">p(M) = \frac{\left( \int_0^T \lambda(t) dt \right)^{M}e^{-\int_0^T \lambda(t) dt}}{M!}.</script>

<p>Notice that this step ignores the <em>timing</em> of the events. Next, calculate the likelihood of the <em>collection</em> of event times <script type="math/tex">\{s_m\}_{m=1}^M</script>. The likelihood of an event at time <script type="math/tex">s</script> is given by <script type="math/tex">\frac{\lambda(s)}{\int_0^T \lambda(t) dt},</script> and therefore a <em>sequence</em> of events has likelihood</p>

<script type="math/tex; mode=display">\prod_{m=1}^M \frac{\lambda(s_m)}{\int_0^T \lambda(t) dt}.</script>

<p>However, the events in <script type="math/tex">\{s_m\}_{m=1}^M</script> are unordered. Thus, we multiply the above likelihood by <script type="math/tex">M!</script> to account for all the possible ways of associating times with events. After simplifying, the overall likelihood is given by</p>

<script type="math/tex; mode=display">L(\{s_m\} \ | \ \lambda) = \exp \left(-\int_0^T \lambda(t) dt \right) \prod_{m=1}^M \lambda(s_m)</script>

<h4 id="example-homogeneous-poisson-process">Example: Homogeneous Poisson Process</h4>
<p>Setting <script type="math/tex">\lambda(t) = \lambda</script> gives us the simplest Poisson process, known as a <em>homogeneous</em> Poisson process. In any interval <script type="math/tex">\left[t, t + \Delta t \right]</script>, the number of events follows a Poisson distribution with intensity <script type="math/tex">\lambda \Delta t</script>. Thus, the mean and variance of the number of events in any period is proportional to the length of the period.</p>

<p>Below is an implementation of the homogeneous Poisson process in Julia. The struct is defined by a single parameter and has methods to simulate a sequence of events as well as calculate the likelihood of events.</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">using</span> <span class="n">Distributions</span>
<span class="k">import</span> <span class="n">Base</span><span class="o">.</span><span class="n">rand</span>

<span class="s">"""
A homogeneous Poisson process.
"""</span>
<span class="k">struct</span><span class="nc"> HomogeneousProcess</span> <span class="o">&lt;:</span> <span class="n">PoissonProcess</span>
    <span class="n">λ</span>
<span class="k">end</span>

<span class="n">intensity</span><span class="x">(</span><span class="n">p</span><span class="o">::</span><span class="n">HomogeneousProcess</span><span class="x">)</span> <span class="o">=</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="n">p</span><span class="o">.</span><span class="n">λ</span>

<span class="k">function</span><span class="nf"> likelihood</span><span class="x">(</span><span class="n">p</span><span class="o">::</span><span class="n">HomogeneousProcess</span><span class="x">,</span> <span class="n">ts</span><span class="x">,</span> <span class="n">T</span><span class="x">)</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">exp</span><span class="x">(</span><span class="o">-</span><span class="n">p</span><span class="o">.</span><span class="n">λ</span> <span class="o">*</span> <span class="n">T</span><span class="x">)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">λ</span> <span class="o">^</span> <span class="n">length</span><span class="x">(</span><span class="n">ts</span><span class="x">)</span>
    <span class="k">return</span> <span class="n">a</span> <span class="o">*</span> <span class="n">b</span>
<span class="k">end</span>

<span class="k">function</span><span class="nf"> rand</span><span class="x">(</span><span class="n">p</span><span class="o">::</span><span class="n">HomogeneousProcess</span><span class="x">,</span> <span class="n">T</span><span class="x">)</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">rand</span><span class="x">(</span><span class="n">Poisson</span><span class="x">(</span><span class="n">p</span><span class="o">.</span><span class="n">λ</span> <span class="o">*</span> <span class="n">T</span><span class="x">))</span>
    <span class="n">ts</span> <span class="o">=</span> <span class="n">rand</span><span class="x">(</span><span class="n">Uniform</span><span class="x">(</span><span class="mi">0</span><span class="x">,</span> <span class="n">T</span><span class="x">),</span> <span class="n">n</span><span class="x">)</span>
    <span class="k">return</span> <span class="n">sort</span><span class="x">(</span><span class="n">ts</span><span class="x">)</span>
<span class="k">end</span>
</code></pre></div></div>

<p>Note that for a homogeneous Poisson process, the second step of generating a random sample amounts to sampling from a uniform distribution on <script type="math/tex">[0, T]</script>. In addition, the likelihood of a homogeneous process simplifies to</p>

<script type="math/tex; mode=display">L(\{s_m\} \ | \ \lambda) = \exp \left(- \lambda T \right) \lambda^M</script>

<p>This likelihood is shownn below as a function of <script type="math/tex">\lambda</script> for a sequence of ten events occuring over the period <script type="math/tex">[0, 10]</script>. For a homogeneous Poisson process, the timing of events is unimportant because they are uniformly distributed throughout time. Notice that the likelihood peaks at an intensity of one, which matches the average rate of events in the sample.</p>

<p><img src="/assets/img/homogeneous-poisson-process-likelihood.svg" alt="homogeneous-poisson-process-likelihood" /></p>

<h2 id="ii-hawkes-processes">II. Hawkes Processes</h2>
<p>Homogeneous Poisson processes wont get us too far. In interesting applications, the probability of events changes over time in response to environmental factors, perhaps dramatically so. We can model such environments through time-varying intensity functions augmented by environmental variables,</p>

<script type="math/tex; mode=display">\lambda(t) = \lambda(t, x_t).</script>

<p>This definition says that the intensity can vary deterministically as a function of time or in response to a <em>state variable</em>, <script type="math/tex">x_t</script>. The relationship between <script type="math/tex">\lambda</script> and <script type="math/tex">x_t</script> can be nonlinear or even time-varying, and the state variable can therefore drive complicated dynamics. However, for some processes the intensity is better characterized as “self-exciting”: when one event occurs, it increases the likelihood of additional events. Hawkes processes are a class of point processes with this property.</p>

<p>Specifically, the intensity of a Hawkes process is defined as</p>

<script type="math/tex; mode=display">% <![CDATA[
\lambda(t) = \lambda^{(0)} + \sum_{s_m < t} w \cdot \theta e^{-\theta (t - s_m)}. %]]></script>

<p>According to this formulation, there is a jump in the intensity immediately following each event. The intensity then decays exponentially towards <script type="math/tex">\lambda^{(0)}</script>. If no events have occured recently, then we expect approximately <script type="math/tex">\lambda^{(0)}</script> events to occur per unit of time, and we therefore refer to <script type="math/tex">\lambda^{(0)}</script> as the <em>baseline intensity</em><sup id="fnref:1"><a href="#fn:1" class="footnote">1</a></sup>.</p>

<p>Notice that <script type="math/tex">\theta e^{-\theta (t - s_m)}</script> is an exponential distribution and therefore integrates to one. As a result, each event occurrence is expected to directly generate an additional <script type="math/tex">w</script> events. Thus, <script type="math/tex">w</script> controls the amount of self-excitation, while <script type="math/tex">\theta</script> controls its timing, with larger values of <script type="math/tex">\theta</script> leading to slower decay.</p>

<p><img src="/assets/img/univariate-hawkes-process-intensity.png" alt="univariate-hawkes-process-intensity" /></p>

<h3 id="simulation-1">Simulation</h3>
<p>Simulation of Hawkes processes is complicated by their autoregressive nature. Previously, we were able to generate a random number of events using the fact that the number of events has a Poisson distribution with mean given by the integrated intensity of the process. In the case of a Hawkes process, the intensity depends on the number of events, so this approach is clearly infeasible.</p>

<p>However, there is an interesting property of Poisson properties that allows us to recover a straight-forward generative model. It turns out that there is no observational difference between a collection of independent Poisson processes and a single Poisson process whose intensity equals the sum of the intensities in the collection. Specifically, suppose a statisticain observe the events (but not the source) from <script type="math/tex">K</script> <em>independent</em> Poisson processes with intensities <script type="math/tex">\lambda_k</script>. From the statistician’s perspective, there is no differences between the <script type="math/tex">K</script> processes and a single process with intensity</p>

<script type="math/tex; mode=display">\lambda_{tot}(t) = \sum_{k=1}^K \lambda_k(t).</script>

<p>This property is known as the <em>Poisson Superposition Principle</em>, and in the case of a univariate Hawkes process it means that we can treat decompose a process into independent components, perform calculations, and then aggregate the results. In particular, every event is associated with either an independent Poisson process defined by its <em>impulse response</em>, <script type="math/tex">w\theta e^{-\theta (t - s_m)},</script> or the baseline intensity, <script type="math/tex">\lambda^{(0)}</script>. Thus, simulating a Hawkes process amounts to simulating these component processes—which can be done using the previous two-step procedure—and then aggregating the results.</p>

<!-- Figure. Hawkes simulation. -->

<h3 id="likelihood-1">Likelihood</h3>
<p>Theoretically, the likelihood calculation for a Hawkes process is identical to the general formula for Poisson processes above. Assume for simplicity that <script type="math/tex">\lambda^{(0)}</script> is constant. Then the likelihood is given by</p>

<script type="math/tex; mode=display">L(\{s_m\} \ | \ \lambda) = \exp \left(-\int_0^T \lambda(t) dt \right) \prod_{m=1}^M \lambda(s_m)</script>

<script type="math/tex; mode=display">% <![CDATA[
= \exp \left(-\int_0^T \lambda^{(0)} dt - \sum_{m=1}^M \int_{s_m}^T h(t - s_m) dt \right) \prod_{m=1}^M \lambda^{(0)} + \sum_{m' < m} h(s_m - s_{m'}) %]]></script>

<p>Generally, we will work with the log-likelihood instead. Taking logs and simplifying the above we get</p>

<script type="math/tex; mode=display">% <![CDATA[
l(\{s_m\} \ | \ \lambda) = \lambda^{(0)}T + wM + \sum_{m=1}^M \log \left( \lambda^{(0)} + \sum_{m' < m} h(s_m - s_{m'}) \right) %]]></script>

<p>In practice, several tricks prove useful in calculating the log-likelihood. First, the integrated intensity is broken down into independent components parts as in the simulation process. Standard integration methods can be used to determine the contribution of the baseline intensity and each of the impulse responses contributes <script type="math/tex">w</script> to the total integrated intensity<sup id="fnref:2"><a href="#fn:2" class="footnote">2</a></sup>.</p>

<p>Second, notice that a naïve calculation of the intensity at event <script type="math/tex">s_m</script> requires us to calculate an intensity for each event that occurred prior to <script type="math/tex">s_m</script>. Thus, the overall intensity calculation scales quadratically in the number of events, <script type="math/tex">M</script>. Later, we will see a algebraic trick to accelerate this calculation.</p>

<p>Finally, it is useful to recognize an alternative interpretation of the likelihood calculation above (this will help with the multivariate case below). Let us introduce an auxillary variable, <script type="math/tex">\omega_m \in {0, 1, \dots, m-1}</script>, which denotes the parent of the <script type="math/tex">m</script>-th event in the generative model. Since each of the impulse response functions represents an independent Poisson process, the likelihood of observing <script type="math/tex">\{s_m \}_{m=1}^M</script> and <script type="math/tex">\{\omega_m \}_{m=1}^M</script> is found by multiplying the likelihoods of the component processes, including the baseline process:</p>

<script type="math/tex; mode=display">\exp \left(-\int_0^T \lambda^{(0)} dt \right) \prod_{\omega_m = 0} \lambda^{(0)} \prod_{m=1}^M \exp \left( -\int_{s_m}^T h(t - s_m) dt \right) \prod_{\omega_{m'} = m} h(s_{m'} - s_m)</script>

<p>Now to get back the likelihood of the observed events, we sum over all possible parent combinations. Recalling that the sum of the products is the product of the sums<sup id="fnref:3"><a href="#fn:3" class="footnote">3</a></sup>, this sum can be shown to equal</p>

<script type="math/tex; mode=display">% <![CDATA[
\exp \left(-\int_0^T \lambda^{(0)} dt \right) \prod_{m=1}^M \exp \left( -\int_{s_m}^T h(t - s_m) dt \right) \prod_{m=1}^M \lambda{(0)} + \sum_{m' < m} h(s_m - s_{m'}). %]]></script>

<p>You can verify that simplifying and taking logs gives the same formula as above for the log-likelihood.</p>

<!-- $$ L(\{s_m\}_{m=1}^M \ | \ \lambda_{tot}) = L(\{ \{s_m\}_{m=1}^{M_k} \}_{k=1}^K \ | \ \{ \lambda_k \}_{k=1}^K) $$ -->

<h4 id="example-hawkes-process-with-homogeneous-baseline">Example: Hawkes Process with Homogeneous Baseline</h4>
<p>The code below demonstrates an implementation of a univariate Hawkes process with a constant baseline intensity. Note that the likelihood calculation is written in a naïve (i.e. <em>slow</em>) fashion.</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">struct</span><span class="nc"> HawkesProcess</span>
    <span class="n">λ0</span><span class="o">::</span><span class="kt">Float64</span>
    <span class="n">W</span><span class="o">::</span><span class="kt">Float64</span>
    <span class="n">θ</span><span class="o">::</span><span class="kt">Float64</span>
<span class="k">end</span>

<span class="k">function</span><span class="nf"> intensity</span><span class="x">(</span><span class="n">p</span><span class="o">::</span><span class="n">HawkesProcess</span><span class="x">,</span> <span class="n">events</span><span class="x">,</span> <span class="n">t0</span><span class="x">)</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="n">events</span> <span class="o">.&lt;</span> <span class="n">t0</span>
    <span class="n">events</span> <span class="o">=</span> <span class="n">events</span><span class="x">[</span><span class="n">idx</span><span class="x">]</span>
    <span class="n">λ</span> <span class="o">=</span> <span class="n">zeros</span><span class="x">(</span><span class="n">nchannels</span><span class="x">)</span>
    <span class="n">ir</span> <span class="o">=</span> <span class="n">impulse_response</span><span class="x">(</span><span class="n">p</span><span class="x">)</span>
    <span class="k">for</span> <span class="n">childchannel</span> <span class="o">=</span> <span class="mi">1</span><span class="o">:</span><span class="n">nchannels</span>
        <span class="k">for</span> <span class="n">parenttime</span> <span class="k">in</span> <span class="n">events</span>
            <span class="n">Δt</span> <span class="o">=</span> <span class="n">t0</span> <span class="o">-</span> <span class="n">parenttime</span>
            <span class="n">λ</span> <span class="o">+=</span> <span class="n">ir</span><span class="x">(</span><span class="n">t0</span> <span class="o">-</span> <span class="n">parenttime</span><span class="x">)</span>
        <span class="k">end</span>
    <span class="k">end</span>
    <span class="k">return</span> <span class="n">p</span><span class="o">.</span><span class="n">λ0</span> <span class="o">+</span> <span class="n">λ</span>
<span class="k">end</span>

<span class="k">function</span><span class="nf"> impulse_response</span><span class="x">(</span><span class="n">p</span><span class="o">::</span><span class="n">HawkesProcess</span><span class="x">)</span>
    <span class="n">P</span> <span class="o">=</span> <span class="n">ExponentialProcess</span><span class="x">(</span><span class="n">p</span><span class="o">.</span><span class="n">W</span><span class="x">,</span> <span class="n">p</span><span class="o">.</span><span class="n">θ</span><span class="x">)</span>
    <span class="k">return</span> <span class="n">intensity</span><span class="o">.</span><span class="x">(</span><span class="n">P</span><span class="x">)</span>
<span class="k">end</span>

<span class="k">struct</span><span class="nc"> ExponentialProcess</span>
    <span class="n">w</span>
    <span class="n">θ</span>  <span class="c"># rate  = 1 / scale</span>
<span class="k">end</span>

<span class="n">intensity</span><span class="x">(</span><span class="n">p</span><span class="o">::</span><span class="n">ExponentialProcess</span><span class="x">)</span> <span class="o">=</span> <span class="n">t</span> <span class="o">-&gt;</span> <span class="n">p</span><span class="o">.</span><span class="n">w</span> <span class="o">*</span> <span class="n">pdf</span><span class="x">(</span><span class="n">Exponential</span><span class="x">(</span><span class="n">p</span><span class="o">.</span><span class="n">θ</span><span class="x">),</span> <span class="n">t</span><span class="x">)</span>

<span class="k">function</span><span class="nf"> loglikelihood</span><span class="x">(</span><span class="n">p</span><span class="o">::</span><span class="n">HawkesProcess</span><span class="x">,</span> <span class="n">events</span><span class="x">,</span> <span class="n">T</span><span class="x">)</span>
    <span class="n">ll</span> <span class="o">=</span> <span class="mf">0.</span>
    <span class="c"># Calculate integrated intensity</span>
    <span class="n">ll</span> <span class="o">-=</span> <span class="n">sum</span><span class="x">(</span><span class="n">p</span><span class="o">.</span><span class="n">λ0</span><span class="x">)</span> <span class="o">*</span> <span class="n">T</span>
    <span class="n">ll</span> <span class="o">-=</span> <span class="n">sum</span><span class="x">(</span><span class="n">p</span><span class="o">.</span><span class="n">W</span> <span class="o">*</span> <span class="n">length</span><span class="x">(</span><span class="n">events</span><span class="x">))</span>
    <span class="c"># Calculate pointwise total intensity TODO: parallelize</span>
    <span class="n">ir</span> <span class="o">=</span> <span class="n">impulse_response</span><span class="x">(</span><span class="n">p</span><span class="x">)</span>
    <span class="k">for</span> <span class="x">(</span><span class="n">childindex</span><span class="x">,</span> <span class="n">childtime</span><span class="x">)</span> <span class="k">in</span> <span class="n">enumerate</span><span class="x">(</span><span class="n">events</span><span class="x">)</span>
        <span class="n">λtot</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">λ0</span>
        <span class="k">if</span> <span class="n">childindex</span> <span class="o">==</span> <span class="mi">1</span>
            <span class="n">ll</span> <span class="o">+=</span> <span class="n">log</span><span class="x">(</span><span class="n">λtot</span><span class="x">)</span>
            <span class="n">continue</span>
        <span class="k">end</span>
        <span class="n">parentindex</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">while</span> <span class="n">parentindex</span> <span class="o">&lt;</span> <span class="n">childindex</span>
            <span class="n">parenttime</span> <span class="o">=</span> <span class="n">events</span><span class="x">[</span><span class="n">parentindex</span><span class="x">]</span>
            <span class="n">Δt</span> <span class="o">=</span> <span class="n">childtime</span> <span class="o">-</span> <span class="n">parenttime</span>
            <span class="n">λtot</span> <span class="o">+=</span> <span class="n">ir</span><span class="x">(</span><span class="n">Δt</span><span class="x">)</span>
            <span class="n">parentindex</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">end</span>
        <span class="n">ll</span> <span class="o">+=</span> <span class="n">log</span><span class="x">(</span><span class="n">λtot</span><span class="x">)</span>
    <span class="k">end</span>
    <span class="k">return</span> <span class="n">ll</span>
<span class="k">end</span>

<span class="k">function</span><span class="nf"> rand</span><span class="x">(</span><span class="n">p</span><span class="o">::</span><span class="n">HawkesProcess</span><span class="x">,</span> <span class="n">T</span><span class="o">::</span><span class="kt">Float64</span><span class="x">)</span>
    <span class="n">events</span> <span class="o">=</span> <span class="kt">Array</span><span class="x">{</span><span class="kt">Float64</span><span class="x">,</span><span class="mi">1</span><span class="x">}()</span>

    <span class="c"># Generate events, starting from exogenous background processes</span>
    <span class="c"># @info "generating exogenous events..."</span>
    <span class="n">parent</span> <span class="o">=</span> <span class="n">HomogeneousProcess</span><span class="x">(</span><span class="n">p</span><span class="o">.</span><span class="n">λ0</span><span class="x">)</span>
    <span class="n">childevents</span> <span class="o">=</span> <span class="n">rand</span><span class="x">(</span><span class="n">parent</span><span class="x">,</span> <span class="n">T</span><span class="x">)</span>
    <span class="c"># @info "&gt; childevents = $childevents"</span>
    <span class="n">append!</span><span class="x">(</span><span class="n">events</span><span class="x">,</span> <span class="n">childevents</span><span class="x">)</span>
    <span class="c"># generate endogenous events</span>
    <span class="n">isempty</span><span class="x">(</span><span class="n">childevents</span><span class="x">)</span> <span class="o">&amp;&amp;</span> <span class="n">continue</span>
    <span class="n">parentevents</span> <span class="o">=</span> <span class="n">childevents</span>
    <span class="k">for</span> <span class="n">parentevent</span> <span class="k">in</span> <span class="n">parentevents</span>
        <span class="c"># @info @sprintf("generating children for event %.2f...", parentevent)</span>
        <span class="n">generate!</span><span class="x">(</span><span class="n">events</span><span class="x">,</span> <span class="n">parentevent</span><span class="x">,</span> <span class="n">p</span><span class="x">,</span> <span class="n">T</span><span class="x">)</span>
    <span class="k">end</span>

    <span class="c"># return sorted events</span>
    <span class="k">return</span> <span class="n">sort</span><span class="x">(</span><span class="n">times</span><span class="x">)</span>
<span class="k">end</span>

<span class="k">function</span><span class="nf"> generate</span><span class="o">!</span><span class="x">(</span><span class="n">events</span><span class="x">,</span> <span class="n">parentevent</span><span class="x">,</span> <span class="n">process</span><span class="o">::</span><span class="n">StandardHawkesProcess</span><span class="x">,</span> <span class="n">T</span><span class="x">)</span>
    <span class="n">t0</span> <span class="o">=</span> <span class="n">parentevent</span>
    <span class="c"># @info "generating children..."</span>
    <span class="n">parent</span> <span class="o">=</span> <span class="n">ExponentialProcess</span><span class="x">(</span><span class="n">process</span><span class="o">.</span><span class="n">w</span><span class="x">,</span> <span class="n">process</span><span class="o">.</span><span class="n">θ</span><span class="x">)</span>
    <span class="n">childevents</span> <span class="o">=</span> <span class="n">t0</span> <span class="o">.+</span> <span class="n">rand</span><span class="x">(</span><span class="n">parent</span><span class="x">,</span> <span class="n">T</span> <span class="o">-</span> <span class="n">t0</span><span class="x">)</span>
    <span class="c"># @info "childevents=$childevents"</span>
    <span class="n">append!</span><span class="x">(</span><span class="n">events</span><span class="x">,</span> <span class="n">childevents</span><span class="x">)</span>
    <span class="n">isempty</span><span class="x">(</span><span class="n">childevents</span><span class="x">)</span> <span class="o">&amp;&amp;</span> <span class="n">continue</span>
    <span class="n">parentevents</span> <span class="o">=</span> <span class="n">childevents</span>
    <span class="k">for</span> <span class="n">parentevent</span> <span class="k">in</span> <span class="n">parentevents</span>
        <span class="c"># @info @sprintf("generating children for event %.2f...", parentevent)</span>
        <span class="n">generate!</span><span class="x">(</span><span class="n">events</span><span class="x">,</span> <span class="n">parentevent</span><span class="x">,</span> <span class="n">process</span><span class="x">,</span> <span class="n">T</span><span class="x">)</span>
    <span class="k">end</span>
    <span class="c"># @info "done."</span>
<span class="k">end</span>
</code></pre></div></div>

<h2 id="iii-multivariate-processes">III. Multivariate Processes</h2>
<p>The concepts above extend to the case where we are interested in the dynamics of multiple time series. In the simplest case, we might model <script type="math/tex">N</script> independent Poisson processes. In this case we can simply simulate indepednent processes and multiply likelihoods to obtain joint likelihoods. The situation is more complicated for multivariate Hawkes processes because the indiviudal series are dependent. But let us first define a multivariate Hawkes process.</p>

<p>A standard multivariate Hawkes process is specified as</p>

<script type="math/tex; mode=display">% <![CDATA[
\lambda_n(t) = \lambda_n^{(0)} + \sum_{s_m < t} W_{c_m \rightarrow n} \cdot \theta_{c_m \rightarrow n} \cdot e^{-\theta_{c_m \rightarrow n} (t - s_m)} %]]></script>

<p>The formula is similar to the univariate case except that we now have <script type="math/tex">N</script> processes (<script type="math/tex">n = 1, \dots, N</script>) and each event amplifies the intensity of every process (in addition to itself). The effect of the <script type="math/tex">n'</script>-th process on the intensity of the <script type="math/tex">n</script>-th process is captured by <script type="math/tex">W_{n' \rightarrow n}</script> and <script type="math/tex">\theta_{n' \rightarrow n}</script>. Clearly the processes are dependent, which complicates the calculation of likelihood, but allows us to model interactions between processes. It is convenient to think of this model as a representing a graph consisting of <script type="math/tex">N</script> nodes with edges connecting each node in both directions.</p>

<p><img src="/assets/img/multivariate-hawkes-process-graph.png" alt="Figure. A graph representation of a multivariate Hawkes process." /></p>

<h3 id="iiia-simulation">III.A. Simulation</h3>
<p>Simulation of a multivariate Hawkes process is handled using a similar approach to the univariate case based on the Poisson Superposition Principle. The only difference is that each event now spawns an independent Poisson process on <em>each</em> of the other <script type="math/tex">N</script> channels.</p>

<p><img src="/assets/img/multivariate-hawkes-process-intensity.png" alt="Figure. An example of the intensity of a multivariate Hawkes process." /></p>

<h3 id="iiib-likelihood">III.B. Likelihood</h3>
<p>Again, we can use the superposition principle to calculate likelihood. Recall that the principle requires <em>independent</em> processes. If we observed the “parent” of each event, <script type="math/tex">\omega_m</script>, then we could calculate the likelihood by computing <script type="math/tex">\lambda_{tot}(s_m)</script> at each <script type="math/tex">s_m</script> and apply the Poisson likelihood formula (noting that the integral of the exponential distribution is easy to compute). Unfortunately, the <script type="math/tex">\omega_m</script> are latent variables in this model. A general strategy in this situtation is to compute the joint probability (i.e. including the latent parents, <script type="math/tex">\omega_m</script>) and then marginalizing over the parent variables to get back the likelihood.</p>

<p>This process works as follows. First, note that the probability that of event <script type="math/tex">m</script> belonging to the process spawned by event <script type="math/tex">m'</script> is given by</p>

<script type="math/tex; mode=display">p(\omega_m = m') = \frac{}{}</script>

<p>That is, by summing over all possible parents at each event (including the background process on the given node).</p>
<ul>
  <li>Applying this to each of the <script type="math/tex">N</script> processes, we get</li>
</ul>

<script type="math/tex; mode=display">L(\{s_m, c_m\} \ | \ \theta, W) = \dots</script>

<!-- ## Combining Network Models and Point Processes
To combine the spike-and-slab network model with the multivariate Hawkes process we simply modify the impulse-response to include the "spike" parameters, $$A_{i, j}$$.

$$ \lambda_n(t) = \lambda_n^{(0)} + \sum_{s_m < t} A_{c_m, n} \cdot W_{c_m, n} \cdot \theta_{c_m, n} \cdot e^{-\theta_{c_m, n} (t - s_m)}, $$

where $$A_{c_m, n} \in \{0, 1\}$$.

- The network model and the temporal model are *almost* disjoint: they connect through the influence of $$A$$ on the latent parent variables. -->

<h2 id="iv-inference">IV. Inference</h2>

<h3 id="maximum-likelihood-estimation-mle">Maximum-Likelihood Estimation (MLE)</h3>
<h3 id="maximum-a-posteriori-estimation-map">Maximum a Posteriori Estimation (MAP)</h3>
<h4 id="markov-chain-monte-carlo-mcmc">Markov Chain Monte Carlo (MCMC)</h4>

<h2 id="v-further-topics">V. Further Topics</h2>
<ul>
  <li>The intensity of a process can be parameterized as a function of exogenous factors:  <script type="math/tex">\lambda(t) = \lambda(x_t, t)</script>.</li>
  <li>We can also construct a model analogous to a hidden Markov model… (write down continuous-time Markov model for <script type="math/tex">x_t</script>)</li>
  <li>We can also construct a model analogous to a state-space model… (write down continuous-time autoregressive model for <script type="math/tex">x_t</script>)</li>
  <li>Do everything in discrete time in next lecture!</li>
</ul>
<div class="footnotes">
  <ol>
    <li id="fn:1">
      <p>Note that we could also make the baseline intensity time-varying, <script type="math/tex">\lambda^{(0)}(t)</script>. <a href="#fnref:1" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:2">
      <p>The contribution is slightly less than <script type="math/tex">w</script> because the exponential kernel has infinite domain and events are measured over a finite time interval. <a href="#fnref:2" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:3">
      <p>That is, if <script type="math/tex">x \in \{x_1, \dots, x_n\}</script> and <script type="math/tex">y \in \{y_1, \dots, y_m\}</script>, then the sum of all possible combinations of <script type="math/tex">x</script> and <script type="math/tex">y</script> is given by <script type="math/tex">(x_1 + \cdots + x_n)(y_1 + \cdots + y_m)</script>. <a href="#fnref:3" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>


        </article>
    </div>

    <div style="position: absolute; width: 200px; top: 0px; left: 860px;">
        <div uk-sticky="offset: 260">
            <ul class="uk-nav uk-nav-default uk-nav-parent-icon tm-nav" uk-scrollspy-nav="closest: li; scroll: true; offset: 100">
                
            </ul>
        </div>
    </div>

    <div id="disqus_thread" class="uk-margin-large-top"></div>
    <script>
        /**
        *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
        *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
        /*
        var disqus_config = function () {
        this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
        this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
        };
        */
        (function() { // DON'T EDIT BELOW THIS LINE
            var d = document, s = d.createElement('script');
            s.src = 'https://katabaticwindblog.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>

</div>


        </div>

        <div class="uk-section uk-section-xsmall tm-footer">
    <div class="uk-container uk-container-small uk-position-relative">
        <ul class="uk-navbar-nav uk-align-center">
            <li>
                <a id="footer-url" href="#">cswaney.github.io</a>
            </li>
            <!-- <li>
                <p class="uk-text-center uk-text-small">Created with <a href="https://getuikit.com" uk-icon="icon: uikit; ratio: 1.0"></a></p>
            </li> -->
        </ul>
    </div>
</div>


        <!-- convert MathJax to KaTex -->
        <script>
          $("script[type='math/tex']").replaceWith(function() {
              var tex = $(this).text();
              return katex.renderToString(tex.replace(/%.*/g, ''), {displayMode: false});
          });

          $("script[type='math/tex; mode=display']").replaceWith(function() {
              var tex = $(this).html();
              return katex.renderToString(tex.replace(/%.*/g, ''), {displayMode: true});
          });
        </script>

    </body>

</html>
