---
layout: post
author: Colin Swaney
title: Event-Driven Bayesian Models (Pt. II)
date: 2020-05-1
categories: [research]
category: research
tags: [machine learning, high-frequency trading]
excerpt: "<p></p>"
---

We left off by introducing a model that combines a network model with a temporal model of event arrivals called a Hawkes model. The intensity of the $$n$$-th node in this model at time $$t$$ is given by

$$ \lambda_n(t) = \lambda_n^{(0)} + \sum_{s_m < t} A_{c_m, n} \cdot W_{c_m, n} \cdot \theta_{c_m, n} \cdot e^{-\theta_{c_m, n} (t - s_m)}, $$

where $$A_{c_m, n} \in \{0, 1\}$$.

Simulating the model is fairly straight-forward using the Poisson Superposition Principle. First, simulate a network $$A$$ according to the generative model chosen (see previous lecture for details). Next, simulate independent events on each node according a to Poisson process with intensity given by the background rate, $$\lambda_{n}^{(0)}$$. Finally, for each event generated by the background process, recursively generate *independent* Poisson processes with intensity given by the impulse response functions.

## Inference
Now suppose we observe a sequence of events $$ \{ s_m, c_m \} $$, where $$c_m \in \{1, \cdots, N\}$$ represents the node of the event. How can we learn about the model parameters? Let's take a look at some of the standard approaches.

### Maximum Likelihood Estimation (MLE)
The classic approach to is to find the parameters $$ \{ \lambda^{(0)}, A, W, \theta \} $$ that maximize the likelihood of the data. This requires us to be above to (at a minimum) evaluate the likelihood given any set of parameter values. One way to accomplish this is by introducing auxillay parent variables $$\omega_m$$ denoting the order of the event that "caused" the $$m$$-th event (or zero is this event occurred on the background process). As the processes directly generated by each parent event are independent, we can apply the Poisson Superposition Principle to compute the likelihood of augmented data:

$$ L( \{s_m, c_m, \omega_m\} \ | \ \lambda^{(0)}, A, W, \theta) = \prod_{n=1}^N \mathcal{PP} \left( \lambda_n^{(0)} \right) \prod_{m=1}^M \mathcal{PP} \left( h_{c_{\omega_m}, c_m} \right)$$

To compute the likelihood, we sum over all possible values of each $$\omega_m$$:

$$ L( \{s_m, c_m, \omega_m\} \ | \ \lambda^{(0)}, A, W, \theta) = \prod_{n=1}^N \mathcal{PP} \left( \lambda_n^{(0)} \right) \prod_{m=1}^M \mathcal{PP} \left( \sum_{\ \omega_m < m} h_{c_{\omega_m}, c_m} \right).$$

The unfortunate feature of this likelihood is that it requires $$\mathcal{O}(M^2)$$ evaluations of impulse-response functions because *every* event prior to the $$m$$-th is a potential parent (despite the fact that the probability decays exponentially). Nonetheless, we can evaluate the likelihood and maximize it numerically using standard methods. **NOTE**: All of the model parameters are constrained to be non-negative!


## Maximum a Posteriori Estimation (MAP)
As an alternative point estimation, we can calculate the parameters that maximize the posterior distribution. Recall that the posterior distribution of a model with likelihood $$p(\mathcal{D} \ | \ \Theta)$$ and prior distribution $$p(\Theta \ | \ \nu)$$ is given by

$$ p(\Theta \ | \ \mathcal{D}, \nu) = \frac{p(\mathcal{D} \ | \ \Theta) p(\Theta \ | \ \nu)}{p(\mathcal{D})}, $$

where $$\mathcal{D}$$ represents the observed data, and $$\nu$$ represents the hyperparameters governing the prior distribution. The denominator is a constant with respect to $$\Theta$$. Thus, maximizing the posterior distribution is equivalent to maximizing the denominator. We have already seen how to calculate the likelihood. Let's introduce priors on the model parameters.

When the impulse-response rate is parameterized as an exponential function, it turns out that the conditional marginal distribution of each of model parameters is conjugate with a Gamma distribution:

$$ \lambda_n^{(0)} \sim Gamma\left(\alpha_0, \beta_0 \right)$$

$$ W_{n, m} \sim Gamma\left(\alpha_W, \beta_W \right)$$ 

$$ \theta_{n, m} \sim Gamma\left(\alpha_\theta, \beta_\theta \right) $$

The priors are independent, and the joint prior is therefore the product of the individual priors. With this information, we can again use standard numerical optimization methods to calculate $$\Theta_{MAP}$$.


## Bayesian Inference
MLE and MAP point estimates provide incomplete pictures of the model parameters. To fully explore the model, we would like to be able to sample from the full (marginal) posterior distributions. We can use the MCMC technique known as Gibbs sampling to do so. (Gibbs sampling works by sampling from the conditional *marginal* distributions, which are often tractable, as is the present case).

Our decision to use gamma priors now allows us to easily sample the conditional marginal distributions, which are all gamma due to conjugacy.

$$ \lambda_n^{(0)} \sim Gamma(\alpha_0 + M_n, \beta_0 + T). $$

Intuitively, the posterior distribution updates the prior belief of $$\alpha_0$$ events per $$\beta_0$$ time periods. Similarly, we have

$$ W_{n,m} \sim Gamma(\alpha_W + M_{n,m}, \beta_0 + M_m). $$

Again, $$W_{n,m}$$ equals the expected number of events on node $$m$$ generated by an event on node $$n$$. The posterior distribution reflects updating beliefs from $$\alpha_W/\beta_W$$ towards the empirical rate, $$M_{n,m} / M_n$$.

Finally, the impulse-response likelihood is also conjugate with its gamma distribution prior...

$$ $$


## Examples
Let's look at some examples of these methods in action...

### MLE


### MAP


### MCMC